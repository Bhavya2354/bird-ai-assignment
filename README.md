ğŸ” Bird Counting and Weight Estimation using Poultry CCTV

Author: Bhavya

Role Applied: Machine Learning / AI Engineer Intern

ğŸ“Œ Problem Statement

The objective of this assignment is to evaluate practical understanding of:

Machine Learning fundamentals

Computer Vision

Object detection and tracking

API development

The task is to build a prototype system that processes a fixed-camera poultry CCTV video and produces:

Bird Counts Over Time

Using object detection and stable tracking IDs

Bird Weight Estimation

Or a clearly defined weight proxy / index

Deliverables

Complete source code

Detailed README.md

Annotated output video

Sample JSON response from a FastAPI service

ğŸ§  Solution Overview & Approach
Key Challenges

Provided dataset link was unavailable

Most public poultry datasets contain images, not videos

No ground-truth bird weight data available

Design Strategy

To address these constraints, the system was designed as an end-to-end CCTV analytics pipeline:

Images â†’ Video â†’ Detection â†’ Tracking â†’ Counting â†’ Weight Proxy â†’ Visualization â†’ API

The focus is on correct system design and explainability, rather than only model training.

ğŸ›  Technology Stack

Python 3.10+

YOLOv8 (Ultralytics) â€“ object detection

OpenCV â€“ video processing & annotation

SORT (Kalman Filter + IoU matching) â€“ tracking

NumPy / SciPy â€“ numerical computation

FastAPI + Uvicorn â€“ API layer

âœ… All tools are open-source
âŒ No Docker used (as per instructions)
âŒ No external paid APIs used
```
ğŸ“ Project Structure
bird-ai-assignemnt/
â”‚
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ app.py                    # FastAPI application
â”œâ”€â”€ run_pipeline.py           # End-to-end pipeline runner
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml           # Thresholds, FPS, paths
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ yolov8n.pt             # Pretrained YOLOv8 model
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ video_reader.py        # Image â†’ video conversion
â”‚   â”œâ”€â”€ detector.py            # YOLO inference wrapper
â”‚   â”œâ”€â”€ tracker.py             # SORT-based tracking logic
â”‚   â”œâ”€â”€ counter.py             # Bird counting logic
â”‚   â”œâ”€â”€ weight_estimator.py    # Weight proxy estimation
â”‚   â”œâ”€â”€ visualizer.py          # Annotated video writer
â”‚   â”œâ”€â”€ utils.py               # Helper utilities
â”‚   â””â”€â”€ sort/
â”‚       â””â”€â”€ sort.py            # SORT tracker (MIT licensed)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ train/images/
â”‚   â”‚   â”œâ”€â”€ valid/images/
â”‚   â”‚   â””â”€â”€ test/images/
â”‚   â”œâ”€â”€ sample_video.mp4       # Generated CCTV-style video
â”‚   â””â”€â”€ README.md              # Dataset source info
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ annotated_videos/
â”‚   â”‚   â””â”€â”€ output.mp4         # Final annotated video
â”‚   â””â”€â”€ json/
â”‚       â””â”€â”€ sample_response.json
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_detector.py
    â”œâ”€â”€ test_tracking.py
    â”œâ”€â”€ test_counting.py
    â””â”€â”€ test_weight.py
```
ğŸ“Š Dataset Used

Since the dataset link provided in the task description was unavailable, the following public open-source dataset was used:

Roboflow â€“ Chicken Detection Dataset

ğŸ”— https://universe.roboflow.com/shashank-l4mfk/chicken-detection-ehuwm-jrr73

Dataset Details

Labeled poultry images

Train / validation / test split

Multiple poses and lighting conditions

Suitable for detection and tracking evaluation

ğŸ§© Implementation Details

This section explains how each requirement was implemented.

1ï¸âƒ£ Image â†’ Video Conversion (CCTV Simulation)

File: src/video_reader.py

Dataset consists of static images

Images are:

Loaded in sorted order

Resized to a fixed resolution

Written sequentially into a video using OpenCV

Why this step is important

Enables realistic tracking behavior

Mimics fixed-camera poultry CCTV footage

Allows count-over-time analysis

Output

data/sample_video.mp4

2ï¸âƒ£ Bird Detection

File: src/detector.py

Uses YOLOv8 pretrained model (yolov8n.pt)

Each frame produces:

Bounding boxes

Confidence scores

Only bird-related detections are retained

YOLOv8 was chosen for its speed, robustness, and generalization.

3ï¸âƒ£ Bird Tracking (Stable IDs)

Files:

src/tracker.py

src/sort/sort.py

Tracking is implemented using SORT (Simple Online and Realtime Tracking), which combines:

Kalman Filter for motion prediction

IoU-based assignment for detection-to-track matching

Each bird receives a persistent ID, enabling identity preservation across frames.

4ï¸âƒ£ Bird Counting Logic

File: src/counter.py

Counting is ID-based, not frame-based

Logic:

When a new tracking ID appears â†’ count increases

Previously seen IDs are ignored

This prevents double-counting even if birds reappear.

5ï¸âƒ£ Weight Estimation (Proxy / Index)

File: src/weight_estimator.py

Real bird weight ground truth is unavailable

A visual proxy is used:

Bounding box area â‰ˆ relative bird size

Output is a weight index, not grams

This mirrors real-world poultry monitoring systems where visual estimation is used initially.

6ï¸âƒ£ Visualization & Annotation

File: src/visualizer.py

Each frame is annotated with:

Bounding boxes

Tracking IDs

Current bird count

Weight proxy index

Annotated frames are written back into a video.

7ï¸âƒ£ End-to-End Pipeline Execution

File: run_pipeline.py

This script:

Loads the generated video

Runs detection, tracking, counting, and weight estimation

Saves the annotated output video

Stores summary statistics for API usage

Command:

python run_pipeline.py

8ï¸âƒ£ API Implementation (FastAPI)

File: app.py

Built using FastAPI

Exposes pipeline results via an HTTP endpoint

Endpoint

GET /analyze

ğŸ“¤ Output Explanation
ğŸ¥ Annotated Output Video

Path

outputs/annotated_videos/output.mp4


Contains

Bird bounding boxes

Unique tracking IDs

Bird count overlay

Weight proxy overlay

Purpose

Visual verification of detection & tracking

Easy inspection by reviewers

Demonstrates correctness of the system

ğŸ“„ API JSON Output

Path

outputs/json/sample_response.json


Sample Response

{
  "total_birds_detected": 12,
  "frames_processed": 217,
  "average_weight_index": 0.74,
  "output_video": "outputs/annotated_videos/output.mp4"
}


Field Explanation

total_birds_detected â†’ Unique birds counted using tracking IDs

frames_processed â†’ Number of frames analyzed

average_weight_index â†’ Mean relative weight proxy

output_video â†’ Path to annotated video

ğŸ“ˆ Accuracy & Validation Notes

Detection accuracy depends on YOLOv8 pretrained performance

Tracking stability validated via stable ID persistence

Counting correctness ensured through ID-based logic

Since labeled video ground truth is unavailable, qualitative validation and visual inspection were used, which is standard for prototype systems.

â–¶ï¸ How to Run the Project (From Scratch)
git clone https://github.com/Bhavya2354/bird-ai-assignment.git
cd bird-ai-assignment
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
python src/video_reader.py
python run_pipeline.py
uvicorn app:app --reload

ğŸ§ª Testing
python tests/test_detector.py
python tests/test_tracking.py
python tests/test_counting.py
python tests/test_weight.py

ğŸ“ Notes

No Docker used

No external APIs used

Fully local and reproducible

Designed for clarity and explainability

âœ… Conclusion

This project demonstrates:

Strong ML and computer vision fundamentals

Correct use of detection and tracking for analytics

Practical system design under real-world constraints

Clean, modular engineering

End-to-end ownership of a production-style prototype

Author: Bhavya

GitHub: https://github.com/Bhavya2354
