ğŸ” Bird Counting and Weight Estimation (Poultry CCTV Analytics)

Author: Bhavya
Role Applied: Machine Learning / AI Engineer Intern

ğŸ“Œ Problem Statement (As Given in the Task)

The objective of this assignment is to evaluate depth in:

Machine Learning fundamentals

Computer Vision

Object Detection & Tracking

API development

The task requires building a prototype system that processes a fixed-camera poultry CCTV video to produce:

Bird Counts Over Time

Using object detection and stable tracking IDs

Bird Weight Estimation

Or a clearly defined weight proxy / index

Deliverables

Full source code

Detailed README.md

Annotated output video

Sample JSON response from an API (FastAPI)

ğŸ§  How I Approached the Problem
Key Constraints & Observations

Real poultry datasets often do not provide labeled videos

Available datasets typically contain images

Ground-truth bird weights are not available

The system must still behave like a real CCTV pipeline

Design Decisions
Requirement	Design Choice	Reason
CCTV video	Image â†’ Video conversion	Simulates fixed-camera footage
Detection	YOLOv8 (pretrained)	Strong generalization, real-time
Tracking	SORT	Stable IDs, lightweight, proven
Counting	Track-ID based logic	Prevents double counting
Weight	Bounding-box area proxy	Realistic visual approximation
API	FastAPI	Lightweight, production-friendly

The system prioritizes end-to-end correctness, explainability, and reproducibility, not just model inference.

ğŸ›  Technology Stack

Python 3.10+

YOLOv8 (Ultralytics) â€“ bird detection

OpenCV â€“ video processing & annotation

SORT (Kalman Filter + IoU matching) â€“ object tracking

NumPy / SciPy â€“ numerical computation

FastAPI + Uvicorn â€“ API service

âœ… All components are open-source
âŒ No Docker used (as per instructions)
âŒ No external paid APIs

ğŸ“ Project Structure
```text
bird-ai-assignemnt/
â”‚
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ app.py                    # FastAPI application
â”œâ”€â”€ run_pipeline.py           # End-to-end pipeline runner
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml           # Thresholds, FPS, model paths
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ yolov8n.pt            # Pretrained YOLOv8 model
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ video_reader.py        # Image â†’ video conversion
â”‚   â”œâ”€â”€ detector.py            # YOLO inference wrapper
â”‚   â”œâ”€â”€ tracker.py             # SORT-based tracking logic
â”‚   â”œâ”€â”€ counter.py             # Bird counting over time
â”‚   â”œâ”€â”€ weight_estimator.py    # Weight proxy logic
â”‚   â”œâ”€â”€ visualizer.py          # Annotated video writer
â”‚   â”œâ”€â”€ utils.py               # Helper utilities
â”‚   â””â”€â”€ sort/
â”‚       â””â”€â”€ sort.py            # SORT tracker (MIT licensed)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ train/images/
â”‚   â”‚   â”œâ”€â”€ valid/images/
â”‚   â”‚   â””â”€â”€ test/images/
â”‚   â”œâ”€â”€ sample_video.mp4       # Generated CCTV-style video
â”‚   â””â”€â”€ README.md              # Dataset source info
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ annotated_videos/
â”‚   â”‚   â””â”€â”€ output.mp4         # Final annotated video
â”‚   â””â”€â”€ json/
â”‚       â””â”€â”€ sample_response.json # Sample API response
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_detector.py
    â”œâ”€â”€ test_tracking.py
    â”œâ”€â”€ test_counting.py
    â””â”€â”€ test_weight.py
```


ğŸ“Š Dataset Used

The dataset link provided in the task description was unavailable at the time of implementation.
Therefore, a public, open-source poultry detection dataset was used.

Roboflow â€“ Chicken Detection Dataset
ğŸ”— https://app.roboflow.com/shashank-l4mfk/chicken-detection-ehuwm-jrr73/

Dataset Characteristics

Labeled poultry images

Train / Validation / Test split

Multiple lighting & posture variations

Suitable for detection model inference

ğŸ¥ Image â†’ Video Conversion (CCTV Simulation)

Because the dataset contains images, a video was created to simulate fixed-camera CCTV footage.

Why this matters

Enables realistic tracking behavior

Allows count-over-time logic

Matches real deployment constraints

Script Used
python src/video_reader.py

Output
data/sample_video.mp4

ğŸ” Detection Module

Model: YOLOv8 (pretrained)

Input: Video frames

Output: Bounding boxes + confidence scores

Only bird-related detections are retained

The detection module is isolated in detector.py for modularity.

ğŸ” Tracking Module (Stable IDs)

Algorithm: SORT (Simple Online and Realtime Tracking)

Uses:

Kalman Filter for motion prediction

IoU-based assignment for matching detections

Why SORT?

Lightweight and fast

Stable IDs across frames

Suitable for real-time poultry analytics

Each bird is assigned a persistent ID, enabling correct counting.

ğŸ”¢ Bird Counting Logic

Counting is not frame-based.

Instead:

Each new tracking ID increments the total count

Reappearing birds are not double-counted

This ensures:

Correct cumulative counts

Robustness to occlusions and motion

Implemented in counter.py.

âš–ï¸ Weight Estimation (Proxy / Index)
Why a proxy?

No ground-truth bird weights available

Real farms often rely on visual estimation

Method Used

Bounding-box area is used as a proxy

Larger visible area â‰ˆ heavier bird

Output is a relative weight index, not grams

This is clearly documented and justified.

ğŸ¨ Annotated Output Video

The final video includes:

Bounding boxes

Tracking IDs

Bird count overlay

Weight proxy overlay

Generate Output
python run_pipeline.py

Output File
outputs/annotated_videos/output.mp4

ğŸŒ API Implementation (FastAPI)

A simple API exposes the results of the pipeline.

Start the Server
uvicorn app:app --reload

Endpoint
GET /analyze

Sample JSON Response
{
  "total_birds_detected": 12,
  "frames_processed": 217,
  "average_weight_index": 0.74,
  "output_video": "outputs/annotated_videos/output.mp4"
}


Saved at:

outputs/json/sample_response.json

ğŸ“ˆ Accuracy & Evaluation Notes

Detection accuracy depends on the pretrained YOLOv8 model

Tracking accuracy validated via:

Stable ID persistence

No ID switching in normal motion

Counting correctness verified by:

Manual frame inspection

ID-based counting logic

Since no labeled video ground truth is available, qualitative evaluation and visual verification were used, which aligns with real-world prototype validation.

â–¶ï¸ How to Run the Project (From Scratch)
1ï¸âƒ£ Clone the repository
git clone https://github.com/Bhavya2354/bird-ai-assignment.git
cd bird-ai-assignment

2ï¸âƒ£ Create virtual environment
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Convert images to video
python src/video_reader.py

5ï¸âƒ£ Run full pipeline
python run_pipeline.py

6ï¸âƒ£ Start API
uvicorn app:app --reload

ğŸ§ª Testing

Each component can be tested independently:

python tests/test_detector.py
python tests/test_tracking.py
python tests/test_counting.py
python tests/test_weight.py

ğŸ“ Notes

No Docker used

No external APIs used

Fully local & reproducible

Code structured for readability and extensibility

âœ… Conclusion

This prototype demonstrates:

Strong ML & computer vision fundamentals

Correct use of detection + tracking for analytics

Realistic system design under dataset constraints

Clean engineering and reproducibility

End-to-end ownership of a production-style pipeline

Author: Bhavya
GitHub: https://github.com/Bhavya2354
